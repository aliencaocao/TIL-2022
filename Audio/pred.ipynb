{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras import models\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "class_index = {0: 'angry', 1: 'fear', 2: 'happy',3: 'neutral', 4: 'sad'}\n",
    "filenames_with_path = tf.io.gfile.glob('data/test/*')\n",
    "filenames = os.listdir('data/test/')\n",
    "sample_rate = 16000\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def preprocess_val(filepath):\n",
    "      wav = tf.io.read_file(filepath)\n",
    "      wav, sr = tf.audio.decode_wav(wav, desired_channels=1)\n",
    "      wav = tf.squeeze(wav, axis=-1)\n",
    "      if no_norm: wav *= 32768.0\n",
    "      sr = tf.cast(sr, dtype=tf.int64)\n",
    "      wav = tfio.audio.resample(wav, rate_in=sr, rate_out=sample_rate)\n",
    "      spectrogram = tfio.audio.spectrogram(wav, nfft=512, window=512, stride=256)\n",
    "      mel_spectrogram = tfio.audio.melscale(spectrogram, rate=sample_rate, mels=128, fmin=80, fmax=7600)\n",
    "\n",
    "      # Augmentations\n",
    "      # mel_spectrogram = tfio.audio.freq_mask(mel_spectrogram, param=10)\n",
    "      # mel_spectrogram = tfio.audio.time_mask(mel_spectrogram, param=10)\n",
    "\n",
    "      # Resizing\n",
    "      mel_spectrogram = tf.expand_dims(mel_spectrogram, axis=-1)\n",
    "      mel_spectrogram = tf.image.resize_with_pad(mel_spectrogram, target_height=224, target_width=224, method=tf.image.ResizeMethod.BILINEAR)  # any sharper resizing method produce black gaps\n",
    "      mel_spectrogram = tf.squeeze(tf.stack([mel_spectrogram, mel_spectrogram, mel_spectrogram], axis=-1))\n",
    "      mel_spectrogram.set_shape([224, 224, 3])\n",
    "      return mel_spectrogram\n",
    "\n",
    "\n",
    "no_norm = True\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(filenames_with_path).map(preprocess_val, num_parallel_calls=-1)\n",
    "test_ds = test_ds.batch(32).cache().prefetch(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "opt = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=5e-5)\n",
    "opt = tfa.optimizers.Lookahead(opt)\n",
    "\n",
    "model1 = models.load_model('models/regnetx016_19epoch_7813_ranger/', compile=False, custom_objects={'Addons>Lookahead': opt})\n",
    "model2 = models.load_model('models/regnetx016_22epoch_7813/', compile=False, custom_objects={'Addons>Lookahead': opt})  # this one seems worse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 4s 55ms/step\n",
      "63/63 [==============================] - 2s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "preds1 = model1.predict(test_ds)\n",
    "preds1 = tf.nn.softmax(preds1, axis=-1)\n",
    "preds2 = model2.predict(test_ds)\n",
    "preds2 = tf.nn.softmax(preds2, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "pred = 0.5 * preds1 + 0.5 * preds2\n",
    "pred_classes = tf.argmax(pred, axis=-1).numpy()\n",
    "pred_classes = [class_index[i] for i in pred_classes]\n",
    "pred_df = pd.DataFrame({'filename': filenames, 'pred': pred_classes})\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.2554890219561%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {(1 - (len(pred_df[pred_df['pred'] != 'angry']) / len(pred_df))) * 100}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}